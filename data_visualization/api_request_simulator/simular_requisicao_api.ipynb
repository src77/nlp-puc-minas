{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import ast\n",
    "from glob import glob\n",
    "from time import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_files(files):\n",
    "    tudo = ''\n",
    "    for i, f in enumerate(files):\n",
    "        with open(f) as file:\n",
    "            t = pd.read_csv(file, usecols=['date','review'])\n",
    "            if i == 0:\n",
    "                tudo = t\n",
    "            else:\n",
    "                tudo = pd.concat([tudo, t], axis=0)\n",
    "    return tudo\n",
    "\n",
    "def request_api(sentences, url = 'http://localhost:8000/v1/all'):\n",
    "    r = requests.post(url, json={\"sentences\":sentences})\n",
    "    r.encoding = 'utf-8'\n",
    "    return json.loads(r.text)\n",
    "\n",
    "def request_from_big_file(file, chunksize):\n",
    "    tudo = []\n",
    "    url = 'http://localhost:8000/v1/clean_text'\n",
    "    for data in pd.read_csv(file, usecols=['date','review'], chunksize=50000):   \n",
    "        sentences = list(data.review.values)\n",
    "        resposta = request_api(sentences)['result']        \n",
    "        clean = request_api(sentences, url)['result']\n",
    "        dates = data.date.values\n",
    "        for i, value in enumerate(clean):\n",
    "            resposta[i]['clean'] = value\n",
    "            resposta[i]['date'] = dates[i]\n",
    "        tudo += resposta\n",
    "    \n",
    "    df = pd.DataFrame(tudo)\n",
    "    df.to_csv('processado.csv', index=False)\n",
    "    df.to_json('all_reviews.json', force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(528942, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomentar linhas abaixo para gerar o arquivo com os dados a ser analisados\n",
    "files = glob('../../data_extraction/csv/app/*.csv')\n",
    "data = join_files(files)\n",
    "data = data.sort_values(by='date')\n",
    "data['datetime'] = pd.to_datetime(data['date'])\n",
    "start_date = '01-01-2019'\n",
    "end_date = '30-04-2020'\n",
    "mask = (data['datetime'] > start_date) & (data['datetime'] <= end_date)\n",
    "data = data[mask]\n",
    "data = data.fillna('')\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "del data['datetime']\n",
    "data.to_csv('all_reviews.csv',index=False)\n",
    "print(data.shape)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo finalizado em 198.4850401878357 seg\n"
     ]
    }
   ],
   "source": [
    "inicio = time()\n",
    "#Processo necessÃ¡rio para nÃ£o gerar estouro de memÃ³ria\n",
    "request_from_big_file('all_reviews.csv',50000)\n",
    "print('Processo finalizado em', time()-inicio, 'seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_full.to_csv('dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_full.to_json('data.json', force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(analise['result'], f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loja = data_full[['date','rating','review','store','version']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loja.to_csv('dados.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d = pd.read_csv('dataset.csv', usecols=['texto','clean','key_words','sent'])\n",
    "d = d.fillna('')\n",
    "d.key_words = d.key_words.apply(ast.literal_eval)\n",
    "res_json = d.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(res_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.to_json('data.json', force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
